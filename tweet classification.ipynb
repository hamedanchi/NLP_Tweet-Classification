{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-05-20T15:25:23.98857Z","iopub.status.busy":"2021-05-20T15:25:23.988237Z","iopub.status.idle":"2021-05-20T15:25:23.993125Z","shell.execute_reply":"2021-05-20T15:25:23.99213Z","shell.execute_reply.started":"2021-05-20T15:25:23.988538Z"},"trusted":true},"outputs":[],"source":["import pandas as pd \n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["#### Loading the data "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:54:37.07484Z","iopub.status.busy":"2021-05-20T15:54:37.07453Z","iopub.status.idle":"2021-05-20T15:54:37.105816Z","shell.execute_reply":"2021-05-20T15:54:37.105073Z","shell.execute_reply.started":"2021-05-20T15:54:37.074811Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv('train.csv',usecols=['id','text','target'])\n","test_df = pd.read_csv('test.csv',usecols=['id','text'])"]},{"cell_type":"markdown","metadata":{},"source":["Show Examples:"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:54:38.255034Z","iopub.status.busy":"2021-05-20T15:54:38.254642Z","iopub.status.idle":"2021-05-20T15:54:38.263408Z","shell.execute_reply":"2021-05-20T15:54:38.262512Z","shell.execute_reply.started":"2021-05-20T15:54:38.254981Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Just happened a terrible car crash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Heard about #earthquake is different cities, s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>there is a forest fire at spot pond, geese are...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9</td>\n","      <td>Apocalypse lighting. #Spokane #wildfires</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                               text\n","0   0                 Just happened a terrible car crash\n","1   2  Heard about #earthquake is different cities, s...\n","2   3  there is a forest fire at spot pond, geese are...\n","3   9           Apocalypse lighting. #Spokane #wildfires\n","4  11      Typhoon Soudelor kills 28 in China and Taiwan"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["test_df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:54:38.794742Z","iopub.status.busy":"2021-05-20T15:54:38.794435Z","iopub.status.idle":"2021-05-20T15:54:38.803121Z","shell.execute_reply":"2021-05-20T15:54:38.802307Z","shell.execute_reply.started":"2021-05-20T15:54:38.794712Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Our Deeds are the Reason of this #earthquake M...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>Forest fire near La Ronge Sask. Canada</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>All residents asked to 'shelter in place' are ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>13,000 people receive #wildfires evacuation or...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                               text  target\n","0   1  Our Deeds are the Reason of this #earthquake M...       1\n","1   4             Forest fire near La Ronge Sask. Canada       1\n","2   5  All residents asked to 'shelter in place' are ...       1\n","3   6  13,000 people receive #wildfires evacuation or...       1\n","4   7  Just got sent this photo from Ruby #Alaska as ...       1"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:54:39.671797Z","iopub.status.busy":"2021-05-20T15:54:39.671484Z","iopub.status.idle":"2021-05-20T15:54:39.676832Z","shell.execute_reply":"2021-05-20T15:54:39.676034Z","shell.execute_reply.started":"2021-05-20T15:54:39.671767Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(7613, 3)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_df.shape"]},{"cell_type":"markdown","metadata":{},"source":["#### We need to do some text cleaning (optional)\n","here some signs and characters need to be removed , again cleaning the text data before training is a good practice well bert is more advanced architecture , it doesn't much affect if we dont do data cleaning \n",", bert dont need extensive text_cleaning because bert comes with 40/60000 words hence its really not necessary to do text_cleaning but removing the special characters are good practice"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: text_hammer in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (0.1.5)\n","Requirement already satisfied: beautifulsoup4==4.9.1 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from text_hammer) (4.9.1)\n","Requirement already satisfied: spacy in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from text_hammer) (3.4.2)\n","Requirement already satisfied: pandas in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from text_hammer) (1.5.1)\n","Requirement already satisfied: numpy in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from text_hammer) (1.23.4)\n","Requirement already satisfied: TextBlob in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from text_hammer) (0.17.1)\n","Requirement already satisfied: soupsieve>1.2 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from beautifulsoup4==4.9.1->text_hammer) (2.3.2.post1)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from pandas->text_hammer) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from pandas->text_hammer) (2.8.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (2.28.1)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (8.1.5)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (1.0.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (2.0.7)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (1.10.2)\n","Requirement already satisfied: pathy>=0.3.5 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (0.6.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (4.64.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (3.0.10)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (2.4.5)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (2.0.8)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (3.3.0)\n","Requirement already satisfied: jinja2 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (3.1.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (3.0.8)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (1.0.9)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (0.4.2)\n","Requirement already satisfied: setuptools in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (65.5.0)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (21.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from spacy->text_hammer) (0.10.1)\n","Requirement already satisfied: nltk>=3.1 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from TextBlob->text_hammer) (3.7)\n","Requirement already satisfied: joblib in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from nltk>=3.1->TextBlob->text_hammer) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from nltk>=3.1->TextBlob->text_hammer) (2022.10.31)\n","Requirement already satisfied: click in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from nltk>=3.1->TextBlob->text_hammer) (8.1.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from packaging>=20.0->spacy->text_hammer) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from pathy>=0.3.5->spacy->text_hammer) (5.2.1)\n","Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy->text_hammer) (4.4.0)\n","Requirement already satisfied: six>=1.5 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->text_hammer) (1.16.0)\n","Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (2.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (1.26.12)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (3.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy->text_hammer) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy->text_hammer) (0.0.3)\n","Requirement already satisfied: colorama in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy->text_hammer) (0.4.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hamed\\anaconda3\\envs\\hugging_face\\lib\\site-packages (from jinja2->spacy->text_hammer) (2.1.1)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install text_hammer \n","\n","import text_hammer as th\n","\n","def text_preprocessing(df,col_name):\n","    column = col_name\n","\n","    df[column] = df[column].apply(lambda x:str(x).lower())\n","    df[column] = df[column].apply(lambda x: th.remove_emails(x))\n","    df[column] = df[column].apply(lambda x: th.remove_special_chars(x))\n","    df[column] = df[column].apply(lambda x: th.remove_accented_chars(x))\n","    \n","    return(df)\n","\n","#train_cleaned_df = text_preprocessing(train_df,'text')\n","#train_cleaned_df[train_cleaned_df.target == 0]\n","#train_df = train_cleaned_df.copy()"]},{"cell_type":"markdown","metadata":{},"source":["here target 1 means we are talking about any accident or disaster and 0 means just a formal tweets with not much attention\n","\n","so far we have cleaned our text data and now lets load our model"]},{"cell_type":"markdown","metadata":{},"source":["#### Loading Pretrained BERT Model"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:55:25.589041Z","iopub.status.busy":"2021-05-20T15:55:25.588702Z","iopub.status.idle":"2021-05-20T15:55:30.215355Z","shell.execute_reply":"2021-05-20T15:55:30.214551Z","shell.execute_reply.started":"2021-05-20T15:55:25.589003Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}],"source":["from transformers import AutoTokenizer,TFBertModel\n","\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","bert = TFBertModel.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:55:30.217055Z","iopub.status.busy":"2021-05-20T15:55:30.216782Z","iopub.status.idle":"2021-05-20T15:55:30.226708Z","shell.execute_reply":"2021-05-20T15:55:30.225828Z","shell.execute_reply.started":"2021-05-20T15:55:30.217029Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'input_ids': [101, 2019, 2742, 1997, 14324, 2986, 1011, 17372, 1999, 14324, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer('an example of bert fine-tuning in bert')"]},{"cell_type":"markdown","metadata":{},"source":["#### Convert Our text data into BERT input format "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:56:06.246431Z","iopub.status.busy":"2021-05-20T15:56:06.246101Z","iopub.status.idle":"2021-05-20T15:56:06.258826Z","shell.execute_reply":"2021-05-20T15:56:06.25783Z","shell.execute_reply.started":"2021-05-20T15:56:06.246402Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["max len of tweets 31\n"]}],"source":["print(\"max len of tweets\",max([len(x.split()) for x in train_df.text]))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:56:10.494795Z","iopub.status.busy":"2021-05-20T15:56:10.494458Z","iopub.status.idle":"2021-05-20T15:56:11.075438Z","shell.execute_reply":"2021-05-20T15:56:11.074155Z","shell.execute_reply.started":"2021-05-20T15:56:10.494765Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': <tf.Tensor: shape=(7613, 36), dtype=int32, numpy=\n","array([[  101,  2256, 15616, ...,     0,     0,     0],\n","       [  101,  3224,  2543, ...,     0,     0,     0],\n","       [  101,  2035,  3901, ...,     0,     0,     0],\n","       ...,\n","       [  101, 23290,  1012, ...,   102,     0,     0],\n","       [  101,  2610, 11538, ...,     0,     0,     0],\n","       [  101,  1996,  6745, ...,     0,     0,     0]])>, 'token_type_ids': <tf.Tensor: shape=(7613, 36), dtype=int32, numpy=\n","array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(7613, 36), dtype=int32, numpy=\n","array([[1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       ...,\n","       [1, 1, 1, ..., 1, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0],\n","       [1, 1, 1, ..., 0, 0, 0]])>}\n"]}],"source":["x_train = tokenizer(\n","    text=train_df.text.tolist(),\n","    padding=True, \n","    max_length=36,\n","    truncation=True,\n","    return_tensors='tf')\n","\n","print(x_train)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:56:12.505382Z","iopub.status.busy":"2021-05-20T15:56:12.504915Z","iopub.status.idle":"2021-05-20T15:56:12.515463Z","shell.execute_reply":"2021-05-20T15:56:12.51408Z","shell.execute_reply.started":"2021-05-20T15:56:12.505341Z"},"trusted":true},"outputs":[{"data":{"text/plain":["TensorShape([7613, 36])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["x_train['input_ids'].shape"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:56:12.872463Z","iopub.status.busy":"2021-05-20T15:56:12.87217Z","iopub.status.idle":"2021-05-20T15:56:12.878885Z","shell.execute_reply":"2021-05-20T15:56:12.877971Z","shell.execute_reply.started":"2021-05-20T15:56:12.872436Z"},"trusted":true},"outputs":[{"data":{"text/plain":["TensorShape([7613, 36])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["x_train['attention_mask'].shape"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:56:13.598859Z","iopub.status.busy":"2021-05-20T15:56:13.598559Z","iopub.status.idle":"2021-05-20T15:56:13.604357Z","shell.execute_reply":"2021-05-20T15:56:13.603462Z","shell.execute_reply.started":"2021-05-20T15:56:13.59883Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["y_train = train_df.target.values\n","y_train"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:56:14.250618Z","iopub.status.busy":"2021-05-20T15:56:14.25031Z","iopub.status.idle":"2021-05-20T15:56:14.259004Z","shell.execute_reply":"2021-05-20T15:56:14.257907Z","shell.execute_reply.started":"2021-05-20T15:56:14.250587Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0    4342\n","1    3271\n","Name: target, dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train_df.target.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["#### Building the model architecture "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:57:34.598389Z","iopub.status.busy":"2021-05-20T15:57:34.598022Z","iopub.status.idle":"2021-05-20T15:57:37.450875Z","shell.execute_reply":"2021-05-20T15:57:37.450061Z","shell.execute_reply.started":"2021-05-20T15:57:34.598354Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from keras import layers\n","from keras.optimizers import Adam\n","\n","max_length = 36\n","\n","input_ids = layers.Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\n","input_mask = layers.Input(shape=(max_length,), dtype=tf.int32, name=\"attention_mask\")\n","\n","embeddings = bert(input_ids,attention_mask = input_mask)[1] #(0 is the last hidden states,1 means pooler_output)\n","\n","out = layers.Dropout(0.1)(embeddings)\n","out = layers.Dense(128, activation='relu')(out)\n","out = layers.Dropout(0.1)(out)\n","out = layers.Dense(32,activation = 'relu')(out)\n","\n","y = layers.Dense(1,activation = 'sigmoid')(out)\n","    \n","model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n","model.layers[2].trainable = True\n","# for training bert our lr must be so small"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:57:37.452743Z","iopub.status.busy":"2021-05-20T15:57:37.452403Z","iopub.status.idle":"2021-05-20T15:57:37.487872Z","shell.execute_reply":"2021-05-20T15:57:37.486915Z","shell.execute_reply.started":"2021-05-20T15:57:37.452707Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_ids (InputLayer)         [(None, 36)]         0           []                               \n","                                                                                                  \n"," attention_mask (InputLayer)    [(None, 36)]         0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n","                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 36,                                                \n","                                768),                                                             \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," dropout_37 (Dropout)           (None, 768)          0           ['tf_bert_model[0][1]']          \n","                                                                                                  \n"," dense (Dense)                  (None, 128)          98432       ['dropout_37[0][0]']             \n","                                                                                                  \n"," dropout_38 (Dropout)           (None, 128)          0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 32)           4128        ['dropout_38[0][0]']             \n","                                                                                                  \n"," dense_2 (Dense)                (None, 1)            33          ['dense_1[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,584,833\n","Trainable params: 109,584,833\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:57:38.340641Z","iopub.status.busy":"2021-05-20T15:57:38.34033Z","iopub.status.idle":"2021-05-20T15:57:38.369109Z","shell.execute_reply":"2021-05-20T15:57:38.368356Z","shell.execute_reply.started":"2021-05-20T15:57:38.340611Z"},"trusted":true},"outputs":[],"source":["optimizer = Adam(\n","    learning_rate=6e-06, # this learning rate is for bert model , taken from huggingface website \n","    epsilon=1e-08,\n","    decay=0.01)\n","\n","# Compile the model\n","model.compile(\n","    optimizer = optimizer,\n","    loss = \"binary_crossentropy\", \n","    metrics = [\"accuracy\"])"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T15:57:55.81306Z","iopub.status.busy":"2021-05-20T15:57:55.812714Z","iopub.status.idle":"2021-05-20T16:27:38.473589Z","shell.execute_reply":"2021-05-20T16:27:38.472821Z","shell.execute_reply.started":"2021-05-20T15:57:55.813027Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","215/215 [==============================] - 85s 321ms/step - loss: 0.5445 - accuracy: 0.7323 - val_loss: 0.4265 - val_accuracy: 0.8110\n","Epoch 2/2\n","215/215 [==============================] - 71s 328ms/step - loss: 0.4263 - accuracy: 0.8210 - val_loss: 0.3954 - val_accuracy: 0.8346\n"]}],"source":["train_history = model.fit(\n","    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n","    y = y_train,\n","    validation_split = 0.1,\n","    epochs=2,\n","    batch_size=32\n",")"]},{"cell_type":"markdown","metadata":{},"source":["#### TESTING PHASE\n","on this phase we will make predictions out of our model and then submit to kaggle comptetions"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T16:27:56.735086Z","iopub.status.busy":"2021-05-20T16:27:56.734631Z","iopub.status.idle":"2021-05-20T16:27:56.756236Z","shell.execute_reply":"2021-05-20T16:27:56.755449Z","shell.execute_reply.started":"2021-05-20T16:27:56.735042Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Just happened a terrible car crash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Heard about #earthquake is different cities, s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>there is a forest fire at spot pond, geese are...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9</td>\n","      <td>Apocalypse lighting. #Spokane #wildfires</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3258</th>\n","      <td>10861</td>\n","      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n","    </tr>\n","    <tr>\n","      <th>3259</th>\n","      <td>10865</td>\n","      <td>Storm in RI worse than last hurricane. My city...</td>\n","    </tr>\n","    <tr>\n","      <th>3260</th>\n","      <td>10868</td>\n","      <td>Green Line derailment in Chicago http://t.co/U...</td>\n","    </tr>\n","    <tr>\n","      <th>3261</th>\n","      <td>10874</td>\n","      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n","    </tr>\n","    <tr>\n","      <th>3262</th>\n","      <td>10875</td>\n","      <td>#CityofCalgary has activated its Municipal Eme...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3263 rows × 2 columns</p>\n","</div>"],"text/plain":["         id                                               text\n","0         0                 Just happened a terrible car crash\n","1         2  Heard about #earthquake is different cities, s...\n","2         3  there is a forest fire at spot pond, geese are...\n","3         9           Apocalypse lighting. #Spokane #wildfires\n","4        11      Typhoon Soudelor kills 28 in China and Taiwan\n","...     ...                                                ...\n","3258  10861  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n","3259  10865  Storm in RI worse than last hurricane. My city...\n","3260  10868  Green Line derailment in Chicago http://t.co/U...\n","3261  10874  MEG issues Hazardous Weather Outlook (HWO) htt...\n","3262  10875  #CityofCalgary has activated its Municipal Eme...\n","\n","[3263 rows x 2 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["test_df"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T16:28:01.454266Z","iopub.status.busy":"2021-05-20T16:28:01.453892Z","iopub.status.idle":"2021-05-20T16:28:01.752447Z","shell.execute_reply":"2021-05-20T16:28:01.751515Z","shell.execute_reply.started":"2021-05-20T16:28:01.454232Z"},"trusted":true},"outputs":[],"source":["x_test = tokenizer(\n","    text=test_df.text.tolist(),\n","    padding=True, \n","    max_length=36,\n","    truncation=True,\n","    return_tensors='tf')\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2021-05-20T16:28:08.223351Z","iopub.status.busy":"2021-05-20T16:28:08.223032Z","iopub.status.idle":"2021-05-20T16:28:30.755136Z","shell.execute_reply":"2021-05-20T16:28:30.754266Z","shell.execute_reply.started":"2021-05-20T16:28:08.223321Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["102/102 [==============================] - 15s 104ms/step\n"]}],"source":["predicted = model.predict({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('hugging_face')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"8ff484045755359a77c0b0f99aaeefb1d38deb5ea4bf0c488c6939d0440d67b5"}}},"nbformat":4,"nbformat_minor":4}
